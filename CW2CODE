#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue April 29 17:10:31 2025

@author: ahmad
"""

# BITTS CW 2
# Topic: How can Café 65 optimize its daily staffing schedule and
# production plan to minimize cost and waste, while meeting customer demand 


#--------------------------
# 1.

import pandas as pd                    
import numpy as np                     
import matplotlib.pyplot as plt         
import seaborn as sns                   
import pulp                             
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression     
from sklearn.ensemble import RandomForestRegressor     
from sklearn.metrics import mean_absolute_error, r2_score  

np.random.seed(15)                     
#--------------------------
# 2. Simulate two months of Café 65 operational data

days    = ["Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"]  
hours   = list(range(8,17))            
weather = ["Sunny","Cloudy","Rainy"]   
price_coffee = 2.5                    
price_pastry = 3.0                     
price_meal   = 5.0                     
records = []                           # list to accumulate simulated rows

for day_idx in range(60):             
    day_name = days[day_idx % 7]      
    for hr in hours:                   
        w = np.random.choice(weather, p=[0.2,0.5,0.3])  #Manchester Weather :)
        base = np.random.randint(30,70)                  
        if w == "Cloudy":                 
            footfall = int(base * 0.9)  # reduce 10% if cloudy
        elif w == "Sunny":
            footfall = int(base * 0.75) # reduce 25% if sunny people more likely to eat out 
        else:
            footfall = base            
        orders = np.random.randint(int(footfall*0.7), int(footfall*0.9)+1)  
        coffee = int(orders * np.random.uniform(0.4,0.6))  
        meal   = int(orders * np.random.uniform(0.2,0.4)) 
        pastry = orders - coffee - meal                   
        staff  = np.random.randint(1,3)                  
        # compute wait time: orders per staff capacity + randomness, clipped 1–10 mins
        wait   = round(np.clip(orders/(staff*10) + np.random.normal(0,1), 1, 10), 2)
        sales  = round(                               
            coffee*price_coffee +
            pastry*price_pastry +
            meal*price_meal, 2
        )
       
        records.append({
            "day": day_name, "hour": hr, "weather": w,
            "footfall": footfall, "orders": orders,
            "avg_wait_time": wait, "num_staff": staff,
            "coffee_orders": coffee, "pastry_orders": pastry,
            "meal_orders": meal, "total_sales": sales
        })

df = pd.DataFrame(records)               
df.to_csv("cafe65_simulated_data.csv", index=False)  
print("Simulation complete. Data saved")

#--------------------------
# 3. Exploratory Data Analysis 

df = pd.read_csv("cafe65_simulated_data.csv")  
sns.set(style="whitegrid")                    

# 3.1 Average sales by hour
avg_hr = df.groupby("hour")["total_sales"].mean()  
plt.figure(figsize=(10,5))
sns.lineplot(x=avg_hr.index, y=avg_hr.values, marker='o')  
plt.title("Average Hourly Sales at Café 65")
plt.xlabel("Hour"); plt.ylabel("Avg Sales (£)")
plt.xticks(hours)
plt.tight_layout(); plt.show()

# 3.2 Average sales by day
order = ["Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"]
avg_day = df.groupby("day")["total_sales"].mean().reindex(order) 
plt.figure(figsize=(10,5))
sns.barplot(x=avg_day.index, y=avg_day.values)
plt.title("Average Daily Sales at Café 65")
plt.xlabel("Day"); plt.ylabel("Avg Sales (£)")
plt.tight_layout(); plt.show()

# 3.3 Wait time vs staff count
plt.figure(figsize=(8,5))
sns.boxplot(x="num_staff", y="avg_wait_time", data=df)
plt.title("Wait Time vs Number of Staff")
plt.xlabel("Number of Staff"); plt.ylabel("Avg Wait Time (min)")
plt.tight_layout(); plt.show()

# 3.4 Correlation heatmap
corr = df[["footfall","orders","avg_wait_time","num_staff","total_sales"]].corr()
plt.figure(figsize=(10,6))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation of Key Metrics")
plt.tight_layout(); plt.show()

#--------------------------
# 4. Predictive modelling: LR vs RF

df_enc = pd.get_dummies(df, columns=["day","weather"], drop_first=True)  
X = df_enc.drop(["avg_wait_time","total_sales"], axis=1)
y = df_enc["avg_wait_time"]

# train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)

# Linear Regression
lr = LinearRegression().fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
mae_lr = mean_absolute_error(y_test, y_pred_lr) 
r2_lr  = r2_score(y_test, y_pred_lr)             

# Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=15).fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
r2_rf  = r2_score(y_test, y_pred_rf)

print(f"Linear Regression -> MAE: {mae_lr:.2f} min | R2: {r2_lr:.2f}")
print(f"Random Forest      -> MAE: {mae_rf:.2f} min | R2: {r2_rf:.2f}")

#--------------------------
# 5. MILP optimisation of staff levels

df_opt = X_test.reset_index(drop=True).copy()
df_opt["pred_wait"] = y_pred_rf               
orig = df.loc[X_test.index].reset_index(drop=True)
df_opt["orders"] = orig["orders"]              

model = pulp.LpProblem("Staff_Opt", pulp.LpMinimize)  
staff_vars = [pulp.LpVariable(f"s_{i}", lowBound=1, upBound=3, cat="Integer")
              for i in range(len(df_opt))]        
model += pulp.lpSum(staff_vars)                 
# capacity constraint: require staff proportional to orders
for i, row in df_opt.iterrows():
    model += staff_vars[i] >= row["orders"] / 20

model.solve()
df_opt["rec_staff"] = [int(v.varValue) for v in staff_vars]  

#--------------------------
# 6. Re-predict and compare before vs after

X_test_upd = X_test.reset_index(drop=True).copy()
X_test_upd["num_staff"] = df_opt["rec_staff"]               

orig = df.loc[X_test.index].reset_index(drop=True)
X_test_upd["day"]     = orig["day"]                         
X_test_upd["weather"] = orig["weather"]                      


X_base = df.drop(["avg_wait_time","total_sales"],axis=1)
train_enc = pd.get_dummies(X_base, columns=["day","weather"], drop_first=True)
test_enc2 = pd.get_dummies(X_test_upd, columns=["day","weather"], drop_first=True)
train_enc = train_enc.loc[:,~train_enc.columns.duplicated()]
test_enc2 = test_enc2.loc[:,~test_enc2.columns.duplicated()]


test_aligned = test_enc2.reindex(columns=train_enc.columns, fill_value=0)


y_after = rf.predict(test_aligned)

# plot comparison
plt.figure(figsize=(14,6))
plt.plot(df_opt["rec_staff"], label="Recommended Staff", color="green")  
plt.plot(y_pred_rf, label="Before Opt", color="orange")
plt.plot(y_after,     label="After Opt",  color="blue")
plt.axhline(2, color="red", linestyle="--", label="2-min target")
plt.title("Predicted Wait: Before vs After Staffing Opt")
plt.xlabel("Hour Index"); plt.ylabel("Wait (min)")
plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

#--------------------------
# 7. Distribution of recommended staff levels

plt.figure(figsize=(8,4))
sns.countplot(x="rec_staff", data=df_opt)
plt.title("Distribution of Recommended Staff Levels")
plt.xlabel("Staff Count"); plt.ylabel("Number of Hours")
plt.tight_layout(); plt.show()
#--------------------------
# 8. Exporting results to CSV


results_df = pd.DataFrame({
    "Model": ["Linear Regression", "Random Forest"],
    "MAE": [mae_lr, mae_rf],
    "R2": [r2_lr, r2_rf]
})
results_df.to_csv("cafe65_model_comparison.csv", index=False)  


pd.DataFrame({
    "Wait_Before_Optimisation": y_pred_rf,
    "Wait_After_Optimisation": y_after,
    "Recommended_Staff": df_opt["rec_staff"]
}).to_csv("cafe65_before_after_optimisation.csv", index=False)


df_opt[["orders", "pred_wait", "rec_staff"]].to_csv("cafe65_staff_plan.csv", index=False)

